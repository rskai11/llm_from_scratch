{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe24330",
   "metadata": {},
   "source": [
    "## **Layer Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca46a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329712d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example=torch.randn(2,5)\n",
    "\n",
    "layer=nn.Sequential(nn.Linear(5,6),nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e514302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out=layer(batch_example)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f52b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "\n",
      " Variance: \n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean=out.mean(dim=-1,keepdim=True)\n",
    "var=out.var(dim=-1,keepdim=True)\n",
    "\n",
    "print(f\"Mean: \\n {mean}\\n\\n Variance: \\n {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6644d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "\n",
      " Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm=(out-mean)/torch.sqrt(var)\n",
    "\n",
    "mean=out_norm.mean(dim=-1,keepdim=True)\n",
    "var=out_norm.var(dim=-1,keepdim=True)\n",
    "\n",
    "print(f\"Mean: \\n {mean}\\n\\n Variance: \\n {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ee8948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "\n",
      " Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "mean=out_norm.mean(dim=-1,keepdim=True)\n",
    "var=out_norm.var(dim=-1,keepdim=True)\n",
    "\n",
    "print(f\"Mean: \\n {mean}\\n\\n Variance: \\n {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implemented\n",
    "# class LayerNorm(nn.Module):\n",
    "#     def __init__(self,emb_dim):\n",
    "#         super().__init__()\n",
    "#         self.eps=1e-5\n",
    "#         self.scale=nn.Parameter(torch.ones(emb_dim))\n",
    "#         self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         mean=x.mean(dim=-1,keepdim=True)\n",
    "#         var=x.var(dim=-1,keepdim=True,unbiased=False)\n",
    "#         norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
    "#         return norm_x * self.scale+ self.shift\n",
    "\n",
    "## Optimized and Production Level\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) * torch.rsqrt(var + self.eps)\n",
    "        return norm_x * self.scale + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ac09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln=LayerNorm(emb_dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361b3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ln=ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef64fb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ln.var(dim=-1,keepdim=True,unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca68437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_from_scratch (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
